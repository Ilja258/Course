{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea0e090",
   "metadata": {},
   "source": [
    "# Итоговый проект на тему \"Отслеживание русского языка жестов\"\n",
    "Модель представляет собой программу по отслеживанию языка жестов при помощи видеокамеры,\n",
    "данные собирались во время использования модели самой программой.\n",
    "\n",
    "Обучение модели происходило на сайте: https://teachablemachine.withgoogle.com/train/image\n",
    "\n",
    "Используемые версии tensorflow и keras: 2.7.0\n",
    "\n",
    "\n",
    "При работе модель будет отображать видео с веб-камеры и обводить прямоугольником кисть с распознанным жестом над которым будет указано название найденного жеста. При зажатии кнопки 'F' жест, не сменяемый на изображении в течение 15 кадров будет записан в переменную, что позволяет после завершения программы увидеть готовую строку из введенных жестов.\n",
    "\n",
    "\n",
    "Дальнейшее развитие может заключаться в применении модели для разбора языка жестов на предзаписанном видео-файле, например при помощи бота telegramm, это позволит людям не знакомым с языком жестов понимать людей его использующих, что улучшит пользовательский опыт людей с ограниченными возможностями при использовании Мессенджера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36d43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "import numpy as np\n",
    "import math\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "classifier = Classifier(\"Model/keras_model.h5\", \"Model/labels.txt\")\n",
    " \n",
    "offset = 20\n",
    "imgSize = 300\n",
    "labels = ['А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'С', 'Ы', ' ', 'И', \"Й\", \"К\", \"Л\", \"Н\", \"М\", \"О\", \"П\", \"Р\", \"Т\",\n",
    "          \"У\", \"Ф\", \"Х\", \"Ц\", \"Ч\",\"Ш\", \"Щ\", \"Ъ\", \"Ь\", \"Э\", \"Ю\", \"Я\"]\n",
    "text = ''\n",
    "warn = 0\n",
    "frameNum =0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "#   Копирование изначального изображения с камеры, чтобы не отправить видимые соединения для предикта модели\n",
    "#   Линии и точки будут рисоваться на отдельном изображении кисти, на основном окне их не будет.\n",
    "    imgOutput = img.copy()\n",
    "    hands, img = detector.findHands(img)\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "        imgCropShape = imgCrop.shape\n",
    " \n",
    "        aspectRatio = h / w\n",
    "        try:\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "                prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "                prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "        except:\n",
    "            if warn == 15:\n",
    "                print('За областью отслеживания!')\n",
    "                warn = 0\n",
    "            \n",
    "#       Обвод кисти в прямоугольник и отображение найденной буквы\n",
    "        cv2.rectangle(imgOutput, (x - offset, y - offset-50),\n",
    "                      (x - offset+90, y - offset-50+50), (255, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(imgOutput, labels[index], (x, y -26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "        cv2.rectangle(imgOutput, (x-offset, y-offset),\n",
    "                      (x + w+offset, y + h+offset), (255, 0, 255), 4)\n",
    "        \n",
    "#       Если жест не изменялся 45 кадров, запоминает его как введенный\n",
    "    if key == ord('f'):\n",
    "        if labels[index] and labels[index] == labels[index]:\n",
    "            if frameNum < 10:\n",
    "                frameNum += 1\n",
    "            else:\n",
    "                frameNum = 0\n",
    "                text = text + str(labels[index])\n",
    "                print(labels[index])        \n",
    "\n",
    "#       Можно раскомментировать стору, чтобы увидеть как модель классифицирует кисть\n",
    "    cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "    cv2.imshow(\"Image\", imgOutput)\n",
    "    key = cv2.waitKey(1)\n",
    "#   Кнопка Q завершает отслеживание и закрывает окна  \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "print(text)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438de56e",
   "metadata": {},
   "source": [
    "# Данная часть отвечает за создание данных для обучения модели\n",
    "\n",
    "при нажатии на кнопку 'S' программа будет находить кисть, выделять ее в отдельное транслируемое окно и сохранять каждый кадр в выбранной папке.\n",
    "Данный метод использовался для обученя модели в связи с отсутствием существующих наборов данных с русским сурдо-алфавиом.\n",
    "Данные для обучения модели собирались вручную и обрабатывались сервисом https://teachablemachine.withgoogle.com/train/image.\n",
    "\n",
    "cvzone - переделанная на основе библиотеки media-pipe от google, библиотека для распознавания кистей рук, была использована в связи с наличием удобных классов классификатора с возможностью подключения модели и работой с меньшей загрузкой системы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86de50b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n"
     ]
    }
   ],
   "source": [
    "# установка и импорт библиотек\n",
    "# !pip install cvzone\n",
    "# !pip install tensorflow==2.7.0\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Создание класса захвата видео с камеры\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Создание класса распознавания рук (ограничение в 1 руку)\n",
    "detector = HandDetector(maxHands=1)\n",
    "\n",
    "# Константы отступа для изображения руки и размера изображения\n",
    "offset = 20\n",
    "imgSize = 256\n",
    "\n",
    "# Константы папки с картинками для модели и обнуление счетчика кадров и ошибок\n",
    "folder = \"data/31\"\n",
    "counter = 0\n",
    "warn = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "        imgCropShape = imgCrop.shape\n",
    "\n",
    "#       Соотношение ширины к длине изображения кисти\n",
    "        aspectRatio = h / w\n",
    "\n",
    "#       Подстройка изображения под заданные размеры, чтобы оно умещалось в окно на белом фоне\n",
    "#       Использовалось для обучения модели и распознавания жестов\n",
    "#       конструкция try используется для предотвращения вылета программы\n",
    "#       при выходе за края области отслеживания\n",
    "        try:\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "        except:\n",
    "            warn += 1\n",
    "            if warn == 15:\n",
    "                print('За областью отслеживания!')\n",
    "                warn = 0\n",
    "            pass\n",
    "#       выводит в отдельное окно рамку с определенным изображением кисти\n",
    "        cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "#   При зажатии 'S' программа будет сохранять изображения руки в папку с data\n",
    "#   Директории в которой расположен блокнот, использовалась для обучения модели\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"s\"):\n",
    "#       Счетчик сделанных кадров\n",
    "        counter += 1\n",
    "        cv2.imwrite(f'{folder}/{counter}.jpg', imgWhite)\n",
    "        print(counter)\n",
    "        \n",
    "#   Кнопка Q завершает отслеживание и закрывает окна  \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490e2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
