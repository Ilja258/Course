{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea0e090",
   "metadata": {},
   "source": [
    "# Итоговый проект на тему \"Отслеживание русского языка жестов\"\n",
    "Модель представляет собой программу по отслеживанию языка жестов при помощи видеокамеры,\n",
    "данные собирались во время использования модели самой программой.\n",
    "\n",
    "Обучение модели происходило на сайте: https://teachablemachine.withgoogle.com/train/image\n",
    "\n",
    "Используемые версии tensorflow и keras: 2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a30b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка и импорт библиотек\n",
    "# !pip install cvzone\n",
    "# !pip install tensorflow==2.7.0\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Создание класса захвата видео с камеры\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Создание класса распознавания рук (ограничение в 1 руку)\n",
    "detector = HandDetector(maxHands=1)\n",
    "\n",
    "# Константы отступа для изображения руки и размера изображения\n",
    "offset = 20\n",
    "imgSize = 256\n",
    "\n",
    "# Константы папки с картинками для модели и обнуление счетчика кадров и ошибок\n",
    "folder = \"data/18\"\n",
    "counter = 0\n",
    "warn = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "        imgCropShape = imgCrop.shape\n",
    "\n",
    "#       Соотношение ширины к длине изображения кисти\n",
    "        aspectRatio = h / w\n",
    "\n",
    "#       Подстройка изображения под заданные размеры, чтобы оно умещалось в окно на белом фоне\n",
    "#       Использовалось для обучения модели и распознавания жестов\n",
    "#       конструкция try используется для предотвращения вылета программы\n",
    "#       при выходе за края области отслеживания\n",
    "        try:\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "        except:\n",
    "            warn += 1\n",
    "            if warn == 15:\n",
    "                print('За областью отслеживания!')\n",
    "                warn = 0\n",
    "            pass\n",
    "        cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "#   При зажатии 'S' программа будет сохранять изображения руки в папку с data\n",
    "#   Директории в которой расположен блокнот, использовалась для обучения модели\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"s\"):\n",
    "#       Счетчик сделанных кадров\n",
    "        counter += 1\n",
    "        cv2.imwrite(f'{folder}/{counter}.jpg', imgWhite)\n",
    "        print(counter)\n",
    "        \n",
    "#   Кнопка Q завершает отслеживание и закрывает окна  \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e36d43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "В\n",
      "В\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "import numpy as np\n",
    "import math\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "classifier = Classifier(\"Model/keras_model.h5\", \"Model/labels.txt\")\n",
    " \n",
    "offset = 20\n",
    "imgSize = 300\n",
    "labels = ['А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'С', 'Ы', ' ', 'И', \"Й\", \"К\", \"Л\", \"Н\", \"М\", \"О\", \"П\"]\n",
    "text = ''\n",
    "warn = 0\n",
    "frameNum =0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "#   Копирование изначального изображения с камеры, чтобы не отправить видимые соединения для предикта модели\n",
    "#   Линии и точки будут рисоваться на \n",
    "    imgOutput = img.copy()\n",
    "    hands, img = detector.findHands(img)\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "        imgCropShape = imgCrop.shape\n",
    " \n",
    "        aspectRatio = h / w\n",
    "        try:\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "                prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "                prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "        except:\n",
    "            if warn == 15:\n",
    "                print('За областью отслеживания!')\n",
    "                warn = 0\n",
    "            \n",
    "#       Обвод кисти в прямоугольник и отображение найденной буквы\n",
    "        cv2.rectangle(imgOutput, (x - offset, y - offset-50),\n",
    "                      (x - offset+90, y - offset-50+50), (255, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(imgOutput, labels[index], (x, y -26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "        cv2.rectangle(imgOutput, (x-offset, y-offset),\n",
    "                      (x + w+offset, y + h+offset), (255, 0, 255), 4)\n",
    "        \n",
    "#       Если жест не изменялся 45 кадров, запоминает его как введенный\n",
    "    if key == ord('f'):\n",
    "        if labels[index] and labels[index] == labels[index]:\n",
    "            if frameNum < 10:\n",
    "                frameNum += 1\n",
    "            else:\n",
    "                frameNum = 0\n",
    "                text = text + str(labels[index])\n",
    "                print(labels[index])        \n",
    "\n",
    "#       Можно раскомментировать стору, чтобы увидеть как модель классифицирует кисть\n",
    "    cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "    cv2.imshow(\"Image\", imgOutput)\n",
    "    key = cv2.waitKey(1)\n",
    "#   Кнопка Q завершает отслеживание и закрывает окна  \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "print(text)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de50b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
